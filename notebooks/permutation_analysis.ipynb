{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "# Kolmogorov-Smirnov Test\n",
    "# The Kolmogorov-Smirnov test compares the data to a normal distribution.\n",
    "from scipy.stats import kstest\n",
    "from itertools import combinations\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "from mne_connectivity import spectral_connectivity_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre (7, 49, 126001)\n",
      "during (5, 49, 126001)\n",
      "post (5, 49, 126001)\n",
      "combine (17, 49, 126001)\n"
     ]
    }
   ],
   "source": [
    "process_epoch_path = \"../processed_epochs.pkl\"\n",
    "with open(process_epoch_path, \"rb\") as f:\n",
    "    epochs = pickle.load(f)\n",
    "\n",
    "for key, value in epochs.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre (2401, 1)\n",
      "during (2401, 1)\n",
      "post (2401, 1)\n",
      "combine (2401, 1)\n"
     ]
    }
   ],
   "source": [
    "# wpli_connectivity_permutation_analysis.pkl\n",
    "# wpli_connectivity.pkl -> The difference is statistically significant\n",
    "# dpli_connectivity.pkl -> -\n",
    "\n",
    "\n",
    "features_path = \"../wpli_connectivity.pkl\"\n",
    "with open(features_path, \"rb\") as f:\n",
    "    features = pickle.load(f)\n",
    "\n",
    "for key, value in features.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lower_triangular(matrix):\n",
    "    return matrix[np.tril_indices(matrix.shape[0], k=-1)]\n",
    "\n",
    "\n",
    "def extract_stage_lower_triangular(connectivity):\n",
    "    return extract_lower_triangular(connectivity.get_data(\"dense\").squeeze())\n",
    "\n",
    "\n",
    "# Step 3: Visualize the fit\n",
    "def plot_fit(data, mean, std_dev, title: str = \"pre\"):\n",
    "    # Plot the histogram of the data with Seaborn\n",
    "    sns.histplot(\n",
    "        data,\n",
    "        bins=30,\n",
    "        kde=False,\n",
    "        stat=\"density\",\n",
    "        color=\"blue\",\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.6,\n",
    "    )\n",
    "\n",
    "    # Plot the PDF of the fitted normal distribution\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = stats.norm.pdf(x, mean, std_dev)\n",
    "    plt.plot(x, p, \"k\", linewidth=2)\n",
    "    title = f\"{title} - Fit results: mean = %.2f,  std dev = %.2f\" % (mean, std_dev)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def ks_test(data):\n",
    "    \"\"\"\n",
    "    Kolmogorov-Smirnov Test\n",
    "    The Kolmogorov-Smirnov test compares the data to a normal\n",
    "    distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like\n",
    "        The data to test for normality.\n",
    "    \"\"\"\n",
    "    stat, p = kstest(data, \"norm\")\n",
    "    print(\"Statistics=%.3f, p=%.3f\" % (stat, p))\n",
    "    if p > 0.05:\n",
    "        print(\"Data is normally distributed (fail to reject H0)\")\n",
    "    else:\n",
    "        print(\"Data is not normally distributed (reject H0)\")\n",
    "\n",
    "\n",
    "def perform_paired_ttest(sample1, sample2, alpha=0.05):\n",
    "    t_statistic, p_value = stats.ttest_rel(sample1, sample2)\n",
    "\n",
    "    return t_statistic, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine if the distributions shown in the histograms are normally distributed, we can visually inspect the histograms and the overlaid density curves, as well as consider the mean and standard deviation provided.\n",
    "\n",
    "First Image:\n",
    "\n",
    "Mean = 0.47\n",
    "Standard Deviation = 0.02\n",
    "Visual Inspection: The histogram appears to have a skew to the right, indicating it might not be perfectly normally distributed. The density curve does not fit perfectly over the histogram, showing some deviation from normality.\n",
    "Second Image:\n",
    "\n",
    "Mean = 0.51\n",
    "Standard Deviation = 0.02\n",
    "Visual Inspection: The histogram looks more symmetric compared to the first one, and the density curve fits better over the histogram. This suggests that the distribution might be closer to a normal distribution.\n",
    "Third Image:\n",
    "\n",
    "Mean = 0.50\n",
    "Standard Deviation = 0.02\n",
    "Visual Inspection: Similar to the second image, this histogram appears quite symmetric, and the density curve fits well over the histogram. This indicates that the distribution is likely to be normally distributed.\n",
    "Based on visual inspection:\n",
    "\n",
    "The second and third images seem to be normally distributed.\n",
    "The first image appears to have some skew and may not be normally distributed.\n",
    "For a more accurate assessment, statistical tests like the Shapiro-Wilk test or the Kolmogorov-Smirnov test could be performed on the data to determine normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether features are distributed normally or not\n",
    "for key, value in features.items():\n",
    "    data = extract_stage_lower_triangular(value)\n",
    "    # filter non-zero values\n",
    "    print(key, data.shape)\n",
    "    mean, std = data.mean(), data.std()\n",
    "\n",
    "    print(f\"Estimated mean: {mean}\")\n",
    "    print(f\"Estimated standard deviation: {std}\")\n",
    "\n",
    "    # print min and max\n",
    "    print(f\"Min: {data.min()}\")\n",
    "    print(f\"Max: {data.max()}\")\n",
    "\n",
    "    ks_test(data)\n",
    "\n",
    "    # Plot the fitted distribution\n",
    "    plot_fit(data, mean, std, title=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate t-test between classes\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# calculate the correlation between the lower triangular matrices\n",
    "correlations = {}\n",
    "for stage1, stage2 in combinations(features.keys(), 2):\n",
    "    print(f\"\\nComparing {stage1} and {stage2}:\")\n",
    "    t_statistic, p_value = perform_paired_ttest(\n",
    "        extract_stage_lower_triangular(features[stage1]),\n",
    "        extract_stage_lower_triangular(features[stage2]),\n",
    "    )\n",
    "\n",
    "    print(\"\\nPaired Samples T-Test Results:\")\n",
    "    print(f\"T-statistic: {t_statistic}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "\n",
    "    if p_value < alpha:\n",
    "        print(f\"The difference is statistically significant (p < {alpha})\")\n",
    "    else:\n",
    "        print(f\"The difference is not statistically significant (p >= {alpha})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate t-test between classes\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# calculate the correlation between the lower triangular matrices\n",
    "correlations = {}\n",
    "for stage1, stage2 in combinations(features.keys(), 2):\n",
    "    print(f\"\\nComparing {stage1} and {stage2}:\")\n",
    "    t_statistic, p_value = wilcoxon(\n",
    "        extract_stage_lower_triangular(features[stage1]),\n",
    "        extract_stage_lower_triangular(features[stage2]),\n",
    "    )\n",
    "\n",
    "    print(\"\\nPaired Samples T-Test Results:\")\n",
    "    print(f\"T-statistic: {t_statistic}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "\n",
    "    if p_value < alpha:\n",
    "        print(f\"The difference is statistically significant (p < {alpha})\")\n",
    "    else:\n",
    "        print(f\"The difference is not statistically significant (p >= {alpha})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing permutation test\n",
    "\n",
    "\n",
    "def calculate_connectivity(epochs, sfreq, fmin, fmax, tmin, method: str = \"wpli\"):\n",
    "\n",
    "    return spectral_connectivity_epochs(\n",
    "        epochs,\n",
    "        method=method,\n",
    "        mode=\"multitaper\",\n",
    "        sfreq=sfreq,\n",
    "        fmin=fmin,\n",
    "        fmax=fmax,\n",
    "        faverage=True,  # Average connectivity scores for each frequency band. If True, the output freqs will be a list with arrays of the frequencies that were averaged.\n",
    "        tmin=tmin,\n",
    "        mt_adaptive=False,  # Use adaptive weights for multitaper\n",
    "        n_jobs=4,\n",
    "    )\n",
    "\n",
    "\n",
    "def permutation_test(epochs, n_permutations=1000, alpha=0.05, *args, **kwargs):\n",
    "    # Combine all data\n",
    "    combined_data = epochs[\"combine\"].copy()\n",
    "\n",
    "    perm_stats_pre_post = []\n",
    "    perm_stats_pre_during = []\n",
    "    perm_stats_during_post = []\n",
    "\n",
    "    for _ in range(n_permutations):\n",
    "        np.random.shuffle(combined_data)\n",
    "        shuffled_pre = combined_data[:7]\n",
    "        shuffled_during = combined_data[7:12]\n",
    "        shuffled_post = combined_data[12:]\n",
    "\n",
    "        perm_wPLI_pre = extract_stage_lower_triangular(\n",
    "            calculate_connectivity(shuffled_pre, *args, **kwargs)\n",
    "        )\n",
    "        perm_wPLI_during = extract_stage_lower_triangular(\n",
    "            calculate_connectivity(shuffled_during, *args, **kwargs)\n",
    "        )\n",
    "        perm_wPLI_post = extract_stage_lower_triangular(\n",
    "            calculate_connectivity(shuffled_post, *args, **kwargs)\n",
    "        )\n",
    "\n",
    "        perm_stats_pre_post.append(\n",
    "            perform_paired_ttest(perm_wPLI_post.flatten(), perm_wPLI_pre.flatten())\n",
    "        )\n",
    "        perm_stats_pre_during.append(\n",
    "            perform_paired_ttest(perm_wPLI_during.flatten(), perm_wPLI_pre.flatten())\n",
    "        )\n",
    "        perm_stats_during_post.append(\n",
    "            perform_paired_ttest(perm_wPLI_post.flatten(), perm_wPLI_during.flatten())\n",
    "        )\n",
    "\n",
    "    # create a dictionary to store the results\n",
    "    results = {\n",
    "        \"pre_post\": perm_stats_pre_post,\n",
    "        \"pre_during\": perm_stats_pre_during,\n",
    "        \"during_post\": perm_stats_during_post,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 500\n",
    "fmin = 8\n",
    "fmax = 50\n",
    "tmin = 0\n",
    "method = \"wpli\"\n",
    "n_permutation = 1\n",
    "\n",
    "permutation_test(\n",
    "    epochs=epochs,\n",
    "    n_permutations=n_permutation,\n",
    "    alpha=0.05,\n",
    "    sfreq=sfreq,\n",
    "    fmin=fmin,\n",
    "    fmax=fmax,\n",
    "    tmin=tmin,\n",
    "    method=method,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "def load_pickle_file(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "    \n",
    "def process_pickle_files(directory, pattern='permutation_results_*.pkl'):\n",
    "    all_data = []\n",
    "    \n",
    "    # Get all matching pickle files in the directory\n",
    "    pickle_files = glob(os.path.join(directory, pattern))\n",
    "    \n",
    "    for file in pickle_files:\n",
    "        data = load_pickle_file(file)\n",
    "        for item in data:\n",
    "            flattened_item = {}\n",
    "            for key, value in item.items():\n",
    "                if isinstance(value, tuple):\n",
    "                    flattened_item[f'{key}_statistic'] = value[0]\n",
    "                    flattened_item[f'{key}_pvalue'] = value[1]\n",
    "                else:\n",
    "                    flattened_item[key] = value\n",
    "            flattened_item['source_file'] = os.path.basename(file)\n",
    "            all_data.append(flattened_item)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "directory = \"/Users/soroush/Documents/Code/freelance-project/vielight/vielight_close_loop/results/permutation_conditions\"\n",
    "df = process_pickle_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_post_statistic</th>\n",
       "      <th>pre_post_pvalue</th>\n",
       "      <th>pre_during_statistic</th>\n",
       "      <th>pre_during_pvalue</th>\n",
       "      <th>during_post_statistic</th>\n",
       "      <th>during_post_pvalue</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.507643</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>204.292899</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-102.240614</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>permutation_results_37.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.083282</td>\n",
       "      <td>8.174306e-280</td>\n",
       "      <td>46.893947</td>\n",
       "      <td>2.081649e-271</td>\n",
       "      <td>5.892808</td>\n",
       "      <td>4.953931e-09</td>\n",
       "      <td>permutation_results_37.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.663983</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>90.099151</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>13.116101</td>\n",
       "      <td>8.890592e-37</td>\n",
       "      <td>permutation_results_37.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174.117323</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>96.456856</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>86.588883</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>permutation_results_37.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119.879075</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>207.020505</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-77.797524</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>permutation_results_37.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pre_post_statistic  pre_post_pvalue  pre_during_statistic  \\\n",
       "0           97.507643     0.000000e+00            204.292899   \n",
       "1           48.083282    8.174306e-280             46.893947   \n",
       "2           98.663983     0.000000e+00             90.099151   \n",
       "3          174.117323     0.000000e+00             96.456856   \n",
       "4          119.879075     0.000000e+00            207.020505   \n",
       "\n",
       "   pre_during_pvalue  during_post_statistic  during_post_pvalue  \\\n",
       "0       0.000000e+00            -102.240614        0.000000e+00   \n",
       "1      2.081649e-271               5.892808        4.953931e-09   \n",
       "2       0.000000e+00              13.116101        8.890592e-37   \n",
       "3       0.000000e+00              86.588883        0.000000e+00   \n",
       "4       0.000000e+00             -77.797524        0.000000e+00   \n",
       "\n",
       "                  source_file  \n",
       "0  permutation_results_37.pkl  \n",
       "1  permutation_results_37.pkl  \n",
       "2  permutation_results_37.pkl  \n",
       "3  permutation_results_37.pkl  \n",
       "4  permutation_results_37.pkl  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['permutation_results_0.pkl', 'permutation_results_1.pkl',\n",
       "       'permutation_results_10.pkl', 'permutation_results_11.pkl',\n",
       "       'permutation_results_12.pkl', 'permutation_results_13.pkl',\n",
       "       'permutation_results_14.pkl', 'permutation_results_15.pkl',\n",
       "       'permutation_results_16.pkl', 'permutation_results_17.pkl',\n",
       "       'permutation_results_18.pkl', 'permutation_results_19.pkl',\n",
       "       'permutation_results_2.pkl', 'permutation_results_20.pkl',\n",
       "       'permutation_results_21.pkl', 'permutation_results_22.pkl',\n",
       "       'permutation_results_23.pkl', 'permutation_results_24.pkl',\n",
       "       'permutation_results_25.pkl', 'permutation_results_26.pkl',\n",
       "       'permutation_results_27.pkl', 'permutation_results_28.pkl',\n",
       "       'permutation_results_29.pkl', 'permutation_results_3.pkl',\n",
       "       'permutation_results_30.pkl', 'permutation_results_31.pkl',\n",
       "       'permutation_results_32.pkl', 'permutation_results_33.pkl',\n",
       "       'permutation_results_34.pkl', 'permutation_results_35.pkl',\n",
       "       'permutation_results_36.pkl', 'permutation_results_37.pkl',\n",
       "       'permutation_results_38.pkl', 'permutation_results_39.pkl',\n",
       "       'permutation_results_4.pkl', 'permutation_results_40.pkl',\n",
       "       'permutation_results_41.pkl', 'permutation_results_42.pkl',\n",
       "       'permutation_results_43.pkl', 'permutation_results_44.pkl',\n",
       "       'permutation_results_45.pkl', 'permutation_results_46.pkl',\n",
       "       'permutation_results_47.pkl', 'permutation_results_48.pkl',\n",
       "       'permutation_results_49.pkl', 'permutation_results_5.pkl',\n",
       "       'permutation_results_50.pkl', 'permutation_results_6.pkl',\n",
       "       'permutation_results_7.pkl', 'permutation_results_8.pkl',\n",
       "       'permutation_results_9.pkl'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"source_file\"].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_during': WilcoxonResult(statistic=18831.0, pvalue=1.3616590055863041e-173),\n",
       " 'pre_post': WilcoxonResult(statistic=41988.0, pvalue=3.6044230110910713e-150),\n",
       " 'during_post': WilcoxonResult(statistic=110922.0, pvalue=1.382048093713617e-90)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\n",
    "    \"/Users/soroush/Documents/Code/freelance-project/vielight/vielight_close_loop/wpli_connectivity.pkl\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    wpli_connectivity = pickle.load(f)\n",
    "\n",
    "triangular_matrice = {\n",
    "    stage: extract_stage_lower_triangular(wpli_connectivity[stage])\n",
    "    for stage in [\"pre\", \"during\", \"post\"]\n",
    "}\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "# calculate the correlation between the lower triangular matrices\n",
    "correlations = {}\n",
    "for stage1, stage2 in combinations(triangular_matrice.keys(), 2):\n",
    "    correlations[f\"{stage1}_{stage2}\"] = wilcoxon(\n",
    "        triangular_matrice[stage1], triangular_matrice[stage2]\n",
    "    )\n",
    "\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=18831.0, pvalue=1.3616590055863041e-173)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations[\"pre_during\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for pre-during: 0.0\n",
      "p-value for pre-post: 0.0\n",
      "p-value for during-post: 0.0\n"
     ]
    }
   ],
   "source": [
    "def calculate_p_value(correlation, statistic):\n",
    "    return np.mean([1 if x >= correlation else 0 for x in statistic])\n",
    "\n",
    "\n",
    "condition = \"pre_during\"\n",
    "p_value_pre_during = calculate_p_value(\n",
    "    correlations[f\"{condition}\"][0], df[f\"{condition}_statistic\"]\n",
    ")\n",
    "\n",
    "condition = \"pre_post\"\n",
    "p_value_pre_post = calculate_p_value(\n",
    "    correlations[f\"{condition}\"][0], df[f\"{condition}_statistic\"]\n",
    ")\n",
    "\n",
    "condition = \"during_post\"\n",
    "p_value_during_post = calculate_p_value(\n",
    "    correlations[f\"{condition}\"][0], df[f\"{condition}_statistic\"]\n",
    ")\n",
    "\n",
    "print(f\"p-value for pre-during: {p_value_pre_during}\")\n",
    "print(f\"p-value for pre-post: {p_value_pre_post}\")\n",
    "print(f\"p-value for during-post: {p_value_during_post}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
